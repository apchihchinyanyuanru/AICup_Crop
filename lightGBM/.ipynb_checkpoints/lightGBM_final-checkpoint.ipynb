{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbw0l9bckzNQ"
   },
   "source": [
    "# LightGBM\n",
    "- Without sample weight\n",
    "    1. **Appearance**, **Times** and **Similarities** feature data without sample weight\n",
    "    2. **Times** and **Similarities** feature data without sample weight\n",
    "    3. **Appearanc**e and **Similarities** feature data without sample weight\n",
    "    4. **Times** and **Similarities of times** feature data without sample weight\n",
    "    5. **Appearance** and **Similarities of appearance** feature data without sample weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIouhf0ykl2e"
   },
   "outputs": [],
   "source": [
    "# load package\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UjkjeDjbk26p"
   },
   "outputs": [],
   "source": [
    "# read stage1 feature data\n",
    "X1_appearance = np.load('./input_feature_data/stage1_appearance_feature.npy')\n",
    "X1_similarity = np.load('./input_feature_data/stage1_similarity_feature.npy')\n",
    "X1_similarity_of_appearance = np.load('./input_feature_data/stage1_similarity_of_appearance_feature.npy')\n",
    "X1_similarity_of_times = np.load('./input_feature_data/stage1_similarity_of_times_feature.npy')\n",
    "X1_times = np.load('./input_feature_data/stage1_times_feature.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_appearance = np.delete(X1_appearance, 1529, 1)\n",
    "X1_appearance = np.delete(X1_appearance, 764, 1)\n",
    "X1_times = np.delete(X1_times, 1529, 1)\n",
    "X1_times = np.delete(X1_times, 764, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nZ969CQjGvQ"
   },
   "outputs": [],
   "source": [
    "# # read stage2 feature data\n",
    "# X2_appearance = np.load('../../appearance_stage2_feature.npy')\n",
    "# X2_similarity = np.load('../../similarity_stage2_feature.npy')\n",
    "# X2_times = np.load('../../times_stage2_feature.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkZvIw_sCdnq"
   },
   "outputs": [],
   "source": [
    "# read answer data\n",
    "y1 = np.load('./input_feature_data/Y1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjsbtUe9k6-K"
   },
   "source": [
    "# 1. Appearance, Times and Similarities feature data without sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JriROBP0au0W"
   },
   "outputs": [],
   "source": [
    "# merge feature data\n",
    "X1 = np.concatenate((X1_similarity, X1_appearance, X1_times), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zlay3y-emtzo"
   },
   "outputs": [],
   "source": [
    "# split data into testing set and training set\n",
    "# 80% of data into the training set, while the rest 20% is used as a testing set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8bIuXvVmxFV"
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "gbm1 = LGBMClassifier(num_leaves=31, learning_rate=0.05, n_estimators=40)\n",
    "gbm1.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7mL8H4UmzJG"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = gbm1.predict(X_test, num_iteration=gbm1.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uDZYEqYm1f9"
   },
   "outputs": [],
   "source": [
    "# accuracy score for the result\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xqg-ow8Im2yP"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_1= classification_report(y_true=y_test, y_pred=y_pred, digits=4)\n",
    "print(report_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCOqv-hsm4Ej",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Feature importances\n",
    "# print('Feature importances:', list(gbm1.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3Fx8FvDm5PY",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # search for better parameter\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# estimator = LGBMClassifier(num_leaves=31)\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.01, 0.05, 0.1, 1],\n",
    "#     'n_estimators': [20, 40]\n",
    "# }\n",
    "# gbm_ = GridSearchCV(estimator, param_grid)\n",
    "# gbm_.fit(X_train, y_train)\n",
    "# print('Best parameters found by grid search are:', gbm_.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiPyFWusbH-y"
   },
   "source": [
    "---\n",
    "# 2. Times and Similarities feature data without sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1-al-T_bTpG",
    "outputId": "0bf12dd7-b91b-4f27-f423-c0083b6859f5"
   },
   "outputs": [],
   "source": [
    "# merge feature data\n",
    "X1 = np.concatenate((X1_similarity, X1_times), axis=1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIOm15fwbTpH"
   },
   "outputs": [],
   "source": [
    "# split data into testing set and training set\n",
    "# 80% of data into the training set, while the rest 20% is used as a testing set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4fbEg8CbTpH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "gbm2 = LGBMClassifier(num_leaves=31, learning_rate=0.05, n_estimators=40)\n",
    "gbm2.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dfy8LCRbTpH"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = gbm2.predict(X_test, num_iteration=gbm2.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifRxnburbTpI"
   },
   "outputs": [],
   "source": [
    "# accuracy score for the result\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXBzljLEbTpI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_2 = classification_report(y_true=y_test, y_pred=y_pred, digits=4)\n",
    "print(report_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pf-Rkj3qbTpI"
   },
   "outputs": [],
   "source": [
    "# # Feature importances\n",
    "# print('Feature importances:', list(gbm2.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAim2-27bTpI"
   },
   "outputs": [],
   "source": [
    "# # search for better parameter\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# estimator = LGBMClassifier(num_leaves=31)\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.01, 0.05, 0.1, 1],\n",
    "#     'n_estimators': [20, 40]\n",
    "# }\n",
    "# gbm_ = GridSearchCV(estimator, param_grid)\n",
    "# gbm_.fit(X_train, y_train)\n",
    "# print('Best parameters found by grid search are:', gbm_.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g51L7aPvm-D7"
   },
   "source": [
    "--- \n",
    "#  3. Appearance and Similarities features data without sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLzuAAjHm-YS"
   },
   "outputs": [],
   "source": [
    "# merge feature data\n",
    "X1 = np.concatenate((X1_similarity, X1_appearance), axis=1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0SxxPvrnB3r"
   },
   "outputs": [],
   "source": [
    "# split data into testing set and training set\n",
    "# 80% of data into the training set, while the rest 20% is used as a testing set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opwAqJIhnEaT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "gbm3 = LGBMClassifier(num_leaves=31, learning_rate=0.05, n_estimators=40)\n",
    "gbm3.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdADRHHxnH8a"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = gbm3.predict(X_test, num_iteration=gbm3.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aB2fL4KnJQx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy score for the result\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vC3VmedunLUp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_3 = classification_report(y_true=y_test, y_pred=y_pred, digits=4)\n",
    "print(report_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RluNpu9nOno",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Feature importances\n",
    "# print('Feature importances:', list(gbm3.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvRbfS7jnUT2"
   },
   "outputs": [],
   "source": [
    "# # search for better parameter\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# estimator = LGBMClassifier(num_leaves=31)\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.01, 0.05, 0.1, 1],\n",
    "#     'n_estimators': [20, 40]\n",
    "# }\n",
    "# gbm_ = GridSearchCV(estimator, param_grid)\n",
    "# gbm_.fit(X_train, y_train)\n",
    "# print('Best parameters found by grid search are:', gbm_.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiPyFWusbH-y"
   },
   "source": [
    "---\n",
    "# 4. Times and Similarities of times feature data without sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1-al-T_bTpG",
    "outputId": "0bf12dd7-b91b-4f27-f423-c0083b6859f5"
   },
   "outputs": [],
   "source": [
    "# merge feature data\n",
    "X1 = np.concatenate((X1_similarity_of_times, X1_times), axis=1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIOm15fwbTpH"
   },
   "outputs": [],
   "source": [
    "# split data into testing set and training set\n",
    "# 80% of data into the training set, while the rest 20% is used as a testing set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4fbEg8CbTpH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "gbm4 = LGBMClassifier(num_leaves=31, learning_rate=0.05, n_estimators=40)\n",
    "gbm4.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dfy8LCRbTpH"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = gbm4.predict(X_test, num_iteration=gbm4.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifRxnburbTpI"
   },
   "outputs": [],
   "source": [
    "# accuracy score for the result\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXBzljLEbTpI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_4 = classification_report(y_true=y_test, y_pred=y_pred, digits=4)\n",
    "print(report_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pf-Rkj3qbTpI"
   },
   "outputs": [],
   "source": [
    "# # Feature importances\n",
    "# print('Feature importances:', list(gbm4.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAim2-27bTpI"
   },
   "outputs": [],
   "source": [
    "# search for better parameter\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# estimator = LGBMClassifier(num_leaves=31)\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.01, 0.05, 0.1, 1],\n",
    "#     'n_estimators': [20, 40]\n",
    "# }\n",
    "# gbm_ = GridSearchCV(estimator, param_grid)\n",
    "# gbm_.fit(X_train, y_train)\n",
    "# print('Best parameters found by grid search are:', gbm_.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g51L7aPvm-D7"
   },
   "source": [
    "--- \n",
    "#  5. Appearance and Similarities of appearance feature data without sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLzuAAjHm-YS"
   },
   "outputs": [],
   "source": [
    "# merge feature data\n",
    "X1 = np.concatenate((X1_similarity_of_appearance, X1_appearance), axis=1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0SxxPvrnB3r"
   },
   "outputs": [],
   "source": [
    "# split data into testing set and training set\n",
    "# 80% of data into the training set, while the rest 20% is used as a testing set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opwAqJIhnEaT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "gbm5 = LGBMClassifier(num_leaves=31, learning_rate=0.05, n_estimators=40)\n",
    "gbm5.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdADRHHxnH8a"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = gbm5.predict(X_test, num_iteration=gbm5.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aB2fL4KnJQx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy score for the result\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vC3VmedunLUp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_5 = classification_report(y_true=y_test, y_pred=y_pred, digits=4)\n",
    "print(report_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RluNpu9nOno",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "# print('Feature importances:', list(gbm5.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvRbfS7jnUT2"
   },
   "outputs": [],
   "source": [
    "# search for better parameter\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# estimator = LGBMClassifier(num_leaves=31)\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.01, 0.05, 0.1, 1],\n",
    "#     'n_estimators': [20, 40]\n",
    "# }\n",
    "# gbm_ = GridSearchCV(estimator, param_grid)\n",
    "# gbm_.fit(X_train, y_train)\n",
    "# print('Best parameters found by grid search are:', gbm_.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Report\n",
    "- Without sample weight\n",
    "    1. **Appearance**, **Times** and **Similarities** feature data without sample weight\n",
    "    2. **Times** and **Similarities** feature data without sample weight\n",
    "    3. **Appearanc**e and **Similarities** feature data without sample weight\n",
    "    4. **Times** and **Similarities of times** feature data without sample weight\n",
    "    5. **Appearance** and **Similarities of appearance** feature data without sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1. Appearance, Times and Similarities feature data without sample weight\\n', report_1)\n",
    "print('\\n\\n2. Times and Similarities feature data without sample weight\\n', report_2)\n",
    "print('\\n\\n3. Appearance and Similarities feature data without sample weight\\n', report_3)\n",
    "print('\\n\\n4. Times and Similarities of times feature data without sample weight\\n', report_4)\n",
    "print('\\n\\n5. Appearance and Similarities of appearance feature data without sample weight\\n', report_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJG6WDRXnZW7"
   },
   "source": [
    "---\n",
    "# Predict stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h09uTSJunZoc"
   },
   "outputs": [],
   "source": [
    "# predict stage 2\n",
    "# NOTICE X2 in different feature data are different\n",
    "Y2 = gbm3.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rwwwLf4na7x"
   },
   "outputs": [],
   "source": [
    "# read in stage 2 labels for final double check\n",
    "\n",
    "stage2_res_df =  pd.read_csv(\"../../output/results_simi_stage2.csv\")\n",
    "stage2_results = pd.Series(Y2)\n",
    "stage2_res_df['Result'] = stage2_results\n",
    "stage2_res_df = stage2_res_df.loc[stage2_res_df['Result'] == 1]\n",
    "stage2_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTNOXi2jncSK"
   },
   "outputs": [],
   "source": [
    "# filter some ugly answers out\n",
    "# stage2_res_df = stage2_res_df.loc[stage2_df.Similarity >= 0.78]\n",
    "# stage2_res_df\n",
    "stage2_res_df.loc[stage2_res_df.Similarity <= 0.78] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aaLGUwbQngr3"
   },
   "outputs": [],
   "source": [
    "# output results\n",
    "stage2_res_df[[\"Test\", \"Reference\"]].to_csv(\"../../output/lightGBM_app_simi_no_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJG6WDRXnZW7"
   },
   "source": [
    "---\n",
    "# Predict stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read stage3 feature data\n",
    "X3_appearance = np.load('./input_feature_data/stage3_appearance_feature.npy')\n",
    "X3_similarity = np.load('./input_feature_data/stage3_similarity_feature.npy')\n",
    "X3_similarity_of_appearance = np.load('./input_feature_data/stage3_similarity_of_appearance_feature.npy')\n",
    "X3_similarity_of_times = np.load('./input_feature_data/stage3_similarity_of_times_feature.npy')\n",
    "X3_times = np.load('./input_feature_data/stage3_times_feature.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_appearance = np.delete(X3_appearance, 1529, 1)\n",
    "X3_appearance = np.delete(X3_appearance, 764, 1)\n",
    "X3_times = np.delete(X3_times, 1529, 1)\n",
    "X3_times = np.delete(X3_times, 764, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge X1\n",
    "X1 = np.concatenate((X1_similarity_of_appearance, X1_appearance), axis=1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge X3\n",
    "X3 = np.concatenate((X3_similarity_of_appearance, X3_appearance), axis=1)\n",
    "X3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model from all X1\n",
    "# train model\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "gbm_final = LGBMClassifier(num_leaves=31, learning_rate=0.05, n_estimators=40)\n",
    "gbm_final.fit(X1, y1, early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h09uTSJunZoc"
   },
   "outputs": [],
   "source": [
    "# predict stage 3\n",
    "# NOTICE X3 in different feature data are different\n",
    "Y3 = gbm_final.predict(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rwwwLf4na7x"
   },
   "outputs": [],
   "source": [
    "# read in stage 2 labels for final double check\n",
    "\n",
    "stage3_res_df =  pd.read_csv(\"../../output/results_gbm_stage3.csv\")\n",
    "stage3_results = pd.Series(Y3)\n",
    "stage3_res_df['Result'] = stage3_results\n",
    "stage3_res_df = stage3_res_df.loc[stage3_res_df['Result'] == 1]\n",
    "stage3_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTNOXi2jncSK"
   },
   "outputs": [],
   "source": [
    "# filter some ugly answers out\n",
    "# stage3_res_df = stage2_res_df.loc[stage3_df.Similarity >= 0.78]\n",
    "# stage3_res_df\n",
    "stage3_res_df.loc[stage3_res_df.Similarity <= 0.78] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aaLGUwbQngr3"
   },
   "outputs": [],
   "source": [
    "# output results\n",
    "stage3_res_df[[\"Test\", \"Reference\"]].to_csv(\"../../output/lightGBM_5_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JO3PfTURnjVu"
   },
   "source": [
    "---\n",
    "# Save Better Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmQCTQNznlfB"
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "import joblib\n",
    "\n",
    "filename = '../../model/lightGBM_app_simi_no_sample_model.sav'\n",
    "joblib.dump(gbm3, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMeKUs8BnnKs"
   },
   "outputs": [],
   "source": [
    "loaded_model = joblib.load(filename)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLs83tmVnozr"
   },
   "source": [
    "---\n",
    "# Compare Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqzaNiRwnpFf"
   },
   "outputs": [],
   "source": [
    "a_df = pd.read_csv(\"../../output/lightGBM_all_no_sample.csv\")\n",
    "b_df = pd.read_csv(\"../../output/lightGBM_app_simi_no_sample.csv\")\n",
    "\n",
    "pd.concat([a_df, b_df]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUdZ-TgXnsl-"
   },
   "outputs": [],
   "source": [
    "# End of file"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "app_simi_heimin_VS_times_simi_heimin_features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
