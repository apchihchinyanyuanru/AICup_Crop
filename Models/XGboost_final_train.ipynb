{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbw0l9bckzNQ"
   },
   "source": [
    "# XGboost\n",
    "- With sample weight\n",
    "    1. **Appearance**, **Times** and **Similarities** feature data with sample weight\n",
    "    2. **Times** and **Similarities** feature data with sample weight\n",
    "    3. **Appearanc**e and **Similarities** feature data with sample weight\n",
    "    4. **Times** and **Similarities of times** feature data with sample weight\n",
    "    5. **Appearance** and **Similarities of appearance** feature data with sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IIouhf0ykl2e"
   },
   "outputs": [],
   "source": [
    "# load package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UjkjeDjbk26p"
   },
   "outputs": [],
   "source": [
    "# read stage1 feature data\n",
    "X1_appearance = np.load('../FeatureExtracting/stage1_appearance_feature.npy')\n",
    "X1_similarity = np.load('../FeatureExtracting/stage1_similarity_feature.npy')\n",
    "X1_similarity_of_appearance = np.load('../FeatureExtracting/stage1_similarity_of_only_appearance.npy')\n",
    "X1_similarity_of_times = np.load('../FeatureExtracting/stage1_similarity_of_only_times.npy')\n",
    "X1_times = np.load('../FeatureExtracting/stage1_times_feature.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete test & ref miss assigning\n",
    "X1_appearance = np.delete(X1_appearance, 1529, 1)\n",
    "X1_appearance = np.delete(X1_appearance, 764, 1)\n",
    "X1_times = np.delete(X1_times, 1529, 1)\n",
    "X1_times = np.delete(X1_times, 764, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QkZvIw_sCdnq"
   },
   "outputs": [],
   "source": [
    "# read answer data\n",
    "y1 = np.load('../FeatureExtracting/Y1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjsbtUe9k6-K"
   },
   "source": [
    "# 1. Appearance, Times and Similarities feature data with sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JriROBP0au0W"
   },
   "outputs": [],
   "source": [
    "# merge feature data\n",
    "X1 = np.concatenate((X1_similarity, X1_appearance, X1_times), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311922, 3065)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Zlay3y-emtzo"
   },
   "outputs": [],
   "source": [
    "# split data into testing set and training set\n",
    "# 70% of data into the training set, while the rest 30% is used as a testing set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3, random_state=345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "f8bIuXvVmxFV",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "train_sample = class_weight.compute_sample_weight('balanced', y_train)\n",
    "test_sample = class_weight.compute_sample_weight('balanced', y_test)\n",
    "xgb1 =  XGBClassifier(seed=1)\n",
    "xgb1.fit(X_train, y_train, sample_weight=train_sample)# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x7mL8H4UmzJG"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = xgb1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of prediction is: 0.9983222373019011\n"
     ]
    }
   ],
   "source": [
    "# accuracy score for the result\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9997    0.9986    0.9992     93151\n",
      "         1.0     0.7562    0.9319    0.8349       426\n",
      "\n",
      "    accuracy                         0.9983     93577\n",
      "   macro avg     0.8779    0.9653    0.9170     93577\n",
      "weighted avg     0.9986    0.9983    0.9984     93577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_1= classification_report(y_true=y_test, y_pred=y_pred, digits=4)\n",
    "print(report_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UmQCTQNznlfB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_XGBOOST.sav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "import joblib\n",
    "\n",
    "filename = '1_XGBOOST.sav'\n",
    "joblib.dump(xgb1, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lMeKUs8BnnKs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = joblib.load(filename)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCOqv-hsm4Ej",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "# print('Feature importances:', list(xgb1.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiPyFWusbH-y"
   },
   "source": [
    "---\n",
    "# 2. Times and Similarities feature data with sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1-al-T_bTpG",
    "outputId": "0bf12dd7-b91b-4f27-f423-c0083b6859f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311922, 1537)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge feature data\n",
    "X1 = np.concatenate((X1_similarity, X1_times), axis=1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mIOm15fwbTpH"
   },
   "outputs": [],
   "source": [
    "# split data into testing set and training set\n",
    "# 70% of data into the training set, while the rest 30% is used as a testing set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3, random_state=345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "a4fbEg8CbTpH",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:59:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "train_sample = class_weight.compute_sample_weight('balanced', y_train)\n",
    "test_sample = class_weight.compute_sample_weight('balanced', y_test)\n",
    "xgb2 =  XGBClassifier(seed=1)\n",
    "xgb2.fit(X_train, y_train, sample_weight=train_sample)# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0dfy8LCRbTpH"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = xgb2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ifRxnburbTpI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of prediction is: 0.9983222373019011\n"
     ]
    }
   ],
   "source": [
    "# accuracy score for the result\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "qXBzljLEbTpI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9997    0.9986    0.9992     93151\n",
      "         1.0     0.7562    0.9319    0.8349       426\n",
      "\n",
      "    accuracy                         0.9983     93577\n",
      "   macro avg     0.8779    0.9653    0.9170     93577\n",
      "weighted avg     0.9986    0.9983    0.9984     93577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_2 = classification_report(y_true=y_test, y_pred=y_pred, digits=4)\n",
    "print(report_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UmQCTQNznlfB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2_XGBOOST.sav']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "import joblib\n",
    "\n",
    "filename = '2_XGBOOST.sav'\n",
    "joblib.dump(xgb2, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lMeKUs8BnnKs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = joblib.load(filename)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCOqv-hsm4Ej",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "# print('Feature importances:', list(xgb2.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g51L7aPvm-D7"
   },
   "source": [
    "--- \n",
    "#  3. Appearance and Similarities features data with sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "dLzuAAjHm-YS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311922, 1537)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge feature data\n",
    "X1 = np.concatenate((X1_similarity, X1_appearance), axis=1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-0SxxPvrnB3r"
   },
   "outputs": [],
   "source": [
    "# split data into testing set and training set\n",
    "# 70% of data into the training set, while the rest 30% is used as a testing set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3, random_state=345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "opwAqJIhnEaT",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:31:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "train_sample = class_weight.compute_sample_weight('balanced', y_train)\n",
    "test_sample = class_weight.compute_sample_weight('balanced', y_test)\n",
    "xgb3 =  XGBClassifier(seed=1)\n",
    "xgb3.fit(X_train, y_train, sample_weight=train_sample)# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wdADRHHxnH8a"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = xgb3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "0aB2fL4KnJQx",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of prediction is: 0.9982581189822285\n"
     ]
    }
   ],
   "source": [
    "# accuracy score for the result\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vC3VmedunLUp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9997    0.9986    0.9991     93151\n",
      "         1.0     0.7505    0.9249    0.8286       426\n",
      "\n",
      "    accuracy                         0.9983     93577\n",
      "   macro avg     0.8751    0.9617    0.9139     93577\n",
      "weighted avg     0.9985    0.9983    0.9983     93577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_3 = classification_report(y_true=y_test, y_pred=y_pred, digits=4)\n",
    "print(report_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3_XGBOOST.sav']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "import joblib\n",
    "\n",
    "filename = '3_XGBOOST.sav'\n",
    "joblib.dump(xgb3, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RluNpu9nOno",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "# print('Feature importances:', list(xgb3.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiPyFWusbH-y"
   },
   "source": [
    "---\n",
    "# 4. Times and Similarities of times feature data with sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1-al-T_bTpG",
    "outputId": "0bf12dd7-b91b-4f27-f423-c0083b6859f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311922, 1534)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge feature data\n",
    "X1 = np.concatenate((X1_similarity_of_times, X1_times), axis=1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "mIOm15fwbTpH"
   },
   "outputs": [],
   "source": [
    "# split data into testing set and training set\n",
    "# 70% of data into the training set, while the rest 30% is used as a testing set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3, random_state=345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "a4fbEg8CbTpH",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:01:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "train_sample = class_weight.compute_sample_weight('balanced', y_train)\n",
    "test_sample = class_weight.compute_sample_weight('balanced', y_test)\n",
    "xgb4 =  XGBClassifier(seed=1)\n",
    "xgb4.fit(X_train, y_train, sample_weight=train_sample)# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "0dfy8LCRbTpH"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = xgb4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ifRxnburbTpI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of prediction is: 0.9981512551161076\n"
     ]
    }
   ],
   "source": [
    "# accuracy score for the result\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "qXBzljLEbTpI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9997    0.9984    0.9991     93151\n",
      "         1.0     0.7321    0.9366    0.8218       426\n",
      "\n",
      "    accuracy                         0.9982     93577\n",
      "   macro avg     0.8659    0.9675    0.9105     93577\n",
      "weighted avg     0.9985    0.9982    0.9983     93577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_4 = classification_report(y_true=y_test, y_pred=y_pred, digits=4)\n",
    "print(report_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4_XGBOOST.sav']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "import joblib\n",
    "\n",
    "filename = '4_XGBOOST.sav'\n",
    "joblib.dump(xgb4, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pf-Rkj3qbTpI"
   },
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "# print('Feature importances:', list(xgb4.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g51L7aPvm-D7"
   },
   "source": [
    "--- \n",
    "#  5. Appearance and Similarities of appearance feature data with sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "dLzuAAjHm-YS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311922, 1534)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge feature data\n",
    "X1 = np.concatenate((X1_similarity_of_appearance, X1_appearance), axis=1)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0SxxPvrnB3r"
   },
   "outputs": [],
   "source": [
    "# # split data into testing set and training set\n",
    "# # 70% of data into the training set, while the rest 30% is used as a testing set.\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.3, random_state=345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to use all the data to train the fifth model\n",
    "X_train = X1\n",
    "y_train = y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "opwAqJIhnEaT",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "train_sample = class_weight.compute_sample_weight('balanced', y_train)\n",
    "#test_sample = class_weight.compute_sample_weight('balanced', y_test)\n",
    "xgb5 =  XGBClassifier(seed=1)\n",
    "xgb5.fit(X_train, y_train, sample_weight=train_sample)# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdADRHHxnH8a"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "# y_pred = xgb5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aB2fL4KnJQx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # accuracy score for the result\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# print('The accuracy of prediction is:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vC3VmedunLUp"
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# report_5 = classification_report(y_true=y_test, y_pred=y_pred, digits=4)\n",
    "# print(report_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5_XGBOOST.sav']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "import joblib\n",
    "\n",
    "filename = '5_XGBOOST.sav'\n",
    "joblib.dump(xgb5, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RluNpu9nOno",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "# print('Feature importances:', list(xgm5.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Report\n",
    "- Without sample weight\n",
    "    1. **Appearance**, **Times** and **Similarities** feature data without sample weight\n",
    "    2. **Times** and **Similarities** feature data without sample weight\n",
    "    3. **Appearanc**e and **Similarities** feature data without sample weight\n",
    "    4. **Times** and **Similarities of times** feature data without sample weight\n",
    "    5. **Appearance** and **Similarities of appearance** feature data without sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('1. Appearance, Times and Similarities feature data without sample weight\\n', report_1)\n",
    "# print('\\n\\n2. Times and Similarities feature data without sample weight\\n', report_2)\n",
    "# print('\\n\\n3. Appearance and Similarities feature data without sample weight\\n', report_3)\n",
    "# print('\\n\\n4. Times and Similarities of times feature data without sample weight\\n', report_4)\n",
    "# print('\\n\\n5. Appearance and Similarities of appearance feature data without sample weight\\n', report_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLs83tmVnozr"
   },
   "source": [
    "---\n",
    "# Compare Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqzaNiRwnpFf"
   },
   "outputs": [],
   "source": [
    "# a_df = pd.read_csv(\"../../output/lightGBM_all_no_sample.csv\")\n",
    "# b_df = pd.read_csv(\"../../output/lightGBM_app_simi_no_sample.csv\")\n",
    "# #\n",
    "# pd.concat([a_df, b_df]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUdZ-TgXnsl-"
   },
   "outputs": [],
   "source": [
    "# End of file"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "app_simi_heimin_VS_times_simi_heimin_features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
